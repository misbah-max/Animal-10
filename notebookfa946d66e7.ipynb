{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad82462",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-30T16:50:44.141846Z",
     "iopub.status.busy": "2026-01-30T16:50:44.141223Z",
     "iopub.status.idle": "2026-01-30T16:51:00.498500Z",
     "shell.execute_reply": "2026-01-30T16:51:00.497491Z"
    },
    "papermill": {
     "duration": 16.362435,
     "end_time": "2026-01-30T16:51:00.500317",
     "exception": false,
     "start_time": "2026-01-30T16:50:44.137882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# T# ====================================================\n",
    "# VETERINARY ANIMAL CLASSIFICATION WITH TRANSFORMERS\n",
    "# Dataset: Animals-10 (Kaggle)\n",
    "# Model: Vision Transformer (ViT) - No Pretrained Weights\n",
    "# Accuracy Target: >85%\n",
    "# Domain: Veterinary (Animal Health & Species Identification)\n",
    "# SDG Alignment: Life on Land (SDG 15)\n",
    "# ====================================================\n",
    "\n",
    "# Install required packages\n",
    "!pip install torch torchvision matplotlib seaborn scikit-learn tqdm pillow pandas -q\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "   \n",
    "            \n",
    "       \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe2c802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T16:51:00.505075Z",
     "iopub.status.busy": "2026-01-30T16:51:00.504692Z",
     "iopub.status.idle": "2026-01-30T16:51:22.383793Z",
     "shell.execute_reply": "2026-01-30T16:51:22.382801Z"
    },
    "papermill": {
     "duration": 21.88344,
     "end_time": "2026-01-30T16:51:22.385365",
     "exception": false,
     "start_time": "2026-01-30T16:51:00.501925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "==================================================\n",
      "LOADING ANIMALS-10 DATASET\n",
      "==================================================\n",
      "‚úì Found dataset at: /kaggle/input/animals10\n",
      "\n",
      "Loading from: /kaggle/input/animals10\n",
      "\n",
      "Exploring directory structure...\n",
      "Found 2 items in directory\n",
      "  translate.py [file]\n",
      "  raw-img/ [directory] - sample: ['cavallo', 'pecora', 'elefante']\n",
      "\n",
      "Loading images...\n",
      "‚úì Loaded 26179 images\n",
      "‚úì Classes: 1\n",
      "‚úì Class names: ['raw-img']\n",
      "\n",
      "Class distribution:\n",
      "  raw-img: 26179 images\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# VETERINARY ANIMAL CLASSIFICATION - FIXED VERSION\n",
    "# Dataset: Animals-10 (Kaggle)\n",
    "# Model: Custom Vision Transformer (No Pretrained Weights)\n",
    "# ====================================================\n",
    "\n",
    "# Install packages\n",
    "!pip install torch torchvision matplotlib seaborn scikit-learn tqdm pillow pandas -q\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ====================================================\n",
    "# 1. LOAD DATASET (FIXED - NO SHELL COMMANDS IN PYTHON INDENTATION)\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"LOADING ANIMALS-10 DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Dataset paths to try\n",
    "dataset_paths = [\n",
    "    \"/kaggle/input/animals10/animals10\",\n",
    "    \"/kaggle/input/animals10\",\n",
    "    \"/kaggle/input/animals-10\",\n",
    "    \"/kaggle/input/animal10\"\n",
    "]\n",
    "\n",
    "data_dir = None\n",
    "for path in dataset_paths:\n",
    "    if os.path.exists(path):\n",
    "        data_dir = path\n",
    "        print(f\"‚úì Found dataset at: {path}\")\n",
    "        break\n",
    "\n",
    "# If not found, show instructions\n",
    "if data_dir is None:\n",
    "    print(\"\\n‚ùå Dataset not found.\")\n",
    "    print(\"\\nüìã PLEASE ADD THIS DATASET:\")\n",
    "    print(\"1. Click '+ Add Data' button on Kaggle\")\n",
    "    print(\"2. Search for 'animals10'\")\n",
    "    print(\"3. Use: https://www.kaggle.com/datasets/alessiocorrado99/animals10\")\n",
    "    print(\"\\nUsing synthetic data for demo...\")\n",
    "    # Create demo data\n",
    "    from torchvision.datasets import FakeData\n",
    "    full_dataset = FakeData(size=2000, image_size=(3, 224, 224), num_classes=10, \n",
    "                           transform=transforms.ToTensor())\n",
    "else:\n",
    "    # Load real dataset\n",
    "    print(f\"\\nLoading from: {data_dir}\")\n",
    "    \n",
    "    # Check what's in the directory (using Python, not shell commands)\n",
    "    print(\"\\nExploring directory structure...\")\n",
    "    try:\n",
    "        items = os.listdir(data_dir)\n",
    "        print(f\"Found {len(items)} items in directory\")\n",
    "        \n",
    "        # Show first 10 items\n",
    "        for i, item in enumerate(items[:10]):\n",
    "            item_path = os.path.join(data_dir, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                sub_items = os.listdir(item_path)[:3]\n",
    "                print(f\"  {item}/ [directory] - sample: {sub_items}\")\n",
    "            else:\n",
    "                print(f\"  {item} [file]\")\n",
    "        \n",
    "        # Load with ImageFolder\n",
    "        print(\"\\nLoading images...\")\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
    "        print(f\"‚úì Loaded {len(full_dataset)} images\")\n",
    "        print(f\"‚úì Classes: {len(full_dataset.classes)}\")\n",
    "        print(f\"‚úì Class names: {full_dataset.classes}\")\n",
    "        \n",
    "        # Show class distribution\n",
    "        print(\"\\nClass distribution:\")\n",
    "        class_counts = {}\n",
    "        for _, label in full_dataset.samples:\n",
    "            class_name = full_dataset.classes[label]\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "        \n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  {cls}: {count} images\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        print(\"Using synthetic data instead...\")\n",
    "        from torchvision.datasets import FakeData\n",
    "        full_dataset = FakeData(size=2000, image_size=(3, 224, 224), num_classes=10, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a60c5",
   "metadata": {
    "papermill": {
     "duration": 0.001228,
     "end_time": "2026-01-30T16:51:22.388035",
     "exception": false,
     "start_time": "2026-01-30T16:51:22.386807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 59760,
     "sourceId": 840806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 43.123681,
   "end_time": "2026-01-30T16:51:24.689200",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T16:50:41.565519",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
